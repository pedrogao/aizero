{
 "cells": [
  {
   "cell_type": "raw",
   "id": "40762353-7cc1-4b34-8572-74a4540b5eb0",
   "metadata": {},
   "source": [
    "人工神经网络（Artificial Neural Networks, ANN）是一种模仿生物神经网络（如大脑）工作方式的算法结构\n",
    "。它由大量的节点（或称为“神经元”）组成，这些节点按层次排列\n",
    "。最简单的神经网络包含一个输入层，一个或多个隐藏层，以及一个输出层\n",
    "。每个节点都通过“权重”和“偏置”，通常称为bias）与其他节点连接，这些权重和偏置是网络通过学习和训练来调整的参数。\n",
    "\n",
    "神经网络的训练通常包括以下几个. ：1. \n",
    "\n",
    "前向传播（Forward Propagation）：数据通过网络流动，每个节点接收输入，进行计算，并传递到3. 下2. 一层。\n",
    "损失计算（Loss Calculation）：网络的输出与真实值进行比较  ，4. 计3. 算误差。\n",
    "反向传播（Backpropagation）：误差信息从输出层反向传播回网络，以计算每个节点的责任或  对5. 误4. 差的贡献。\n",
    "参数更新（Parameter Update）：使用如梯度下降的优化算法，根据其任调整每个节\n",
    "\n",
    "点的权重使置。\n",
    "现在，我将用 Python 实现一个简单的神经网络，包含前向传播、误差计算、反向传播和参数更新这几个基本部分。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62322329-95d4-491f-a431-ae1f5fe24d19",
   "metadata": {},
   "source": [
    "## 前向传播\n",
    "\n",
    "sigmoid 激活函数：\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "sigmoid 导数：\n",
    "$$\n",
    "x*(1-x)\n",
    "$$\n",
    "\n",
    "核心：\n",
    "矩阵计算\n",
    "\n",
    "输入：input\n",
    "首先计算隐藏层数据：\n",
    "$$\n",
    "hidden = sigmoid(input * w1 + b1)\n",
    "$$\n",
    "\n",
    "参数更新规则：\n",
    "\n",
    "1. 权重更新：\n",
    "\n",
    "$$ w = w - \\alpha \\cdot \\frac{\\partial L}{\\partial w} $$\n",
    "\n",
    "2. 偏置更新：\n",
    "\n",
    "$$ b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b} $$\n",
    "\n",
    "$w$表示权重\n",
    "\n",
    "$b$表示偏置\n",
    "\n",
    "$\\alpha$ 表示学习率\n",
    "\n",
    "$\\frac{\\partial L}{\\partial }$ 是损失函数对权重 $w$ 的偏导数\n",
    "\n",
    "$\\frac{\\partial L}{\\partial }$ 是损失函数对 $b$ 的偏导数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8834c0a-2cbe-4ef4-9bc7-50d8a9f0232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02628811],\n",
       "       [0.97395472],\n",
       "       [0.97397188],\n",
       "       [0.02821358]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # 初始化权重和偏置\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
    "        self.bias1 = np.random.randn(hidden_size)\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
    "        self.bias2 = np.random.randn(output_size)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # 激活函数\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        # Sigmoid 激活函数的导数\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        # 前向传播\n",
    "        # hidden = sigmoid(i * w1 + b1)\n",
    "        self.hidden = self.sigmoid(np.dot(input_data, self.weights1) + self.bias1)\n",
    "        # output = sigmoid(hidden * w2 + b2)\n",
    "        output = self.sigmoid(np.dot(self.hidden, self.weights2) + self.bias2)\n",
    "        return output\n",
    "\n",
    "    def backpropagation(self, input_data, output, expected_output):\n",
    "        # 反向传播\n",
    "        # 计算误差\n",
    "        # 损失函数：如方差计算等\n",
    "        error = expected_output - output\n",
    "        # 反向传播误差并计算梯度\n",
    "        d_weights2 = np.dot(self.hidden.T, (2 * error * self.sigmoid_derivative(output)))\n",
    "        d_bias2 = 2 * error * self.sigmoid_derivative(output)\n",
    "        d_weights1 = np.dot(input_data.T,  (np.dot(2 * error * self.sigmoid_derivative(output), self.weights2.T) * self.sigmoid_derivative(self.hidden)))\n",
    "        d_bias1 = np.dot(2 * error * self.sigmoid_derivative(output), self.weights2.T) * self.sigmoid_derivative(self.hidden)\n",
    "\n",
    "        # 更新权重和偏置\n",
    "        self.weights1 += d_weights1\n",
    "        self.bias1 += d_bias1.sum(axis=0)\n",
    "        self.weights2 += d_weights2\n",
    "        self.bias2 += d_bias2.sum(axis=0)\n",
    "\n",
    "    def train(self, input_data, expected_output):\n",
    "        output = self.forward_propagation(input_data)\n",
    "        self.backpropagation(input_data, output, expected_output)\n",
    "\n",
    "# 示例：一个简单的神经网络，输入层大小为 2，隐藏层大小为 3，输出层大小为 1\n",
    "nn = SimpleNeuralNetwork(input_size=2, hidden_size=3, output_size=1)\n",
    "\n",
    "# 示例数据\n",
    "input_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "expected_output = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# 训练网络\n",
    "for _ in range(1000):\n",
    "    nn.train(input_data, expected_output)\n",
    "\n",
    "# 测试网络\n",
    "output = nn.forward_propagation(input_data)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf0018-a661-43cc-bd6e-0310dfdfcf21",
   "metadata": {},
   "source": [
    "**网络结构**  \n",
    "\n",
    "将上述神经网络结构可视化为：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1df1de-18d3-4c13-9d3c-e32a70540459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Simple Neural Network\n",
      "digraph {\n",
      "\trankdir=LR\n",
      "\tI1 [label=\"input 1\"]\n",
      "\tI2 [label=\"input 2\"]\n",
      "\tH1 [label=\"hidden 1\"]\n",
      "\tH2 [label=\"hidden 2\"]\n",
      "\tH3 [label=\"hidden 3\"]\n",
      "\tO1 [label=output]\n",
      "\tI1 -> H1\n",
      "\tI1 -> H2\n",
      "\tI1 -> H3\n",
      "\tI2 -> H1\n",
      "\tI2 -> H2\n",
      "\tI2 -> H3\n",
      "\tH1 -> O1\n",
      "\tH2 -> O1\n",
      "\tH3 -> O1\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"354pt\" height=\"152pt\"\n viewBox=\"0.00 0.00 354.28 152.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 148)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-148 350.28,-148 350.28,4 -4,4\"/>\n<!-- I1 -->\n<g id=\"node1\" class=\"node\">\n<title>I1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"44.2\" cy=\"-99\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"44.2\" y=\"-95.3\" font-family=\"Times,serif\" font-size=\"14.00\">input 1</text>\n</g>\n<!-- H1 -->\n<g id=\"node3\" class=\"node\">\n<title>H1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"175.74\" cy=\"-126\" rx=\"51.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"175.74\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\">hidden 1</text>\n</g>\n<!-- I1&#45;&gt;H1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>I1&#45;&gt;H1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M84.06,-107.1C95.71,-109.53 108.69,-112.23 121.1,-114.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"120.4,-118.25 130.91,-116.86 121.83,-111.4 120.4,-118.25\"/>\n</g>\n<!-- H2 -->\n<g id=\"node4\" class=\"node\">\n<title>H2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"175.74\" cy=\"-72\" rx=\"51.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"175.74\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">hidden 2</text>\n</g>\n<!-- I1&#45;&gt;H2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>I1&#45;&gt;H2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M84.06,-90.9C95.71,-88.47 108.69,-85.77 121.1,-83.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.83,-86.6 130.91,-81.14 120.4,-79.75 121.83,-86.6\"/>\n</g>\n<!-- H3 -->\n<g id=\"node5\" class=\"node\">\n<title>H3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"175.74\" cy=\"-18\" rx=\"51.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"175.74\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">hidden 3</text>\n</g>\n<!-- I1&#45;&gt;H3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>I1&#45;&gt;H3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M69.65,-84.22C75.83,-80.35 82.41,-76.1 88.39,-72 104.89,-60.69 107.53,-55.76 124.39,-45 128.26,-42.53 132.37,-40.08 136.52,-37.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"138.51,-40.6 145.55,-32.69 135.11,-34.48 138.51,-40.6\"/>\n</g>\n<!-- I2 -->\n<g id=\"node2\" class=\"node\">\n<title>I2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"44.2\" cy=\"-45\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"44.2\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">input 2</text>\n</g>\n<!-- I2&#45;&gt;H1 -->\n<g id=\"edge4\" class=\"edge\">\n<title>I2&#45;&gt;H1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M69.65,-59.78C75.83,-63.65 82.41,-67.9 88.39,-72 104.89,-83.31 107.53,-88.24 124.39,-99 128.26,-101.47 132.37,-103.92 136.52,-106.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"135.11,-109.52 145.55,-111.31 138.51,-103.4 135.11,-109.52\"/>\n</g>\n<!-- I2&#45;&gt;H2 -->\n<g id=\"edge5\" class=\"edge\">\n<title>I2&#45;&gt;H2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M84.06,-53.1C95.71,-55.53 108.69,-58.23 121.1,-60.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"120.4,-64.25 130.91,-62.86 121.83,-57.4 120.4,-64.25\"/>\n</g>\n<!-- I2&#45;&gt;H3 -->\n<g id=\"edge6\" class=\"edge\">\n<title>I2&#45;&gt;H3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M84.06,-36.9C95.71,-34.47 108.69,-31.77 121.1,-29.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.83,-32.6 130.91,-27.14 120.4,-25.75 121.83,-32.6\"/>\n</g>\n<!-- O1 -->\n<g id=\"node6\" class=\"node\">\n<title>O1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"304.68\" cy=\"-72\" rx=\"41.69\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"304.68\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">output</text>\n</g>\n<!-- H1&#45;&gt;O1 -->\n<g id=\"edge7\" class=\"edge\">\n<title>H1&#45;&gt;O1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M209.1,-112.23C226.08,-105.01 247.01,-96.11 264.86,-88.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"266.58,-91.58 274.42,-84.45 263.84,-85.14 266.58,-91.58\"/>\n</g>\n<!-- H2&#45;&gt;O1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>H2&#45;&gt;O1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M227.27,-72C235.73,-72 244.5,-72 252.96,-72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"253.08,-75.5 263.08,-72 253.08,-68.5 253.08,-75.5\"/>\n</g>\n<!-- H3&#45;&gt;O1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>H3&#45;&gt;O1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M209.1,-31.77C226.08,-38.99 247.01,-47.89 264.86,-55.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"263.84,-58.86 274.42,-59.55 266.58,-52.42 263.84,-58.86\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc078323250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def create_neural_network_graph():\n",
    "    # 创建 Digraph 对象\n",
    "    dot = Digraph(comment='Simple Neural Network')\n",
    "\n",
    "    # 设置图的方向为从左到右\n",
    "    dot.attr(rankdir='LR')\n",
    "\n",
    "    # 添加输入层节点\n",
    "    dot.node('I1', 'input 1')\n",
    "    dot.node('I2', 'input 2')\n",
    "\n",
    "    # 添加隐藏层节点\n",
    "    dot.node('H1', 'hidden 1')\n",
    "    dot.node('H2', 'hidden 2')\n",
    "    dot.node('H3', 'hidden 3')\n",
    "\n",
    "    # 添加输出层节点\n",
    "    dot.node('O1', 'output')\n",
    "\n",
    "    # 添加边，表示节点之间的连接\n",
    "    # 输入层到隐藏层的连接\n",
    "    dot.edge('I1', 'H1')\n",
    "    dot.edge('I1', 'H2')\n",
    "    dot.edge('I1', 'H3')\n",
    "    dot.edge('I2', 'H1')\n",
    "    dot.edge('I2', 'H2')\n",
    "    dot.edge('I2', 'H3')\n",
    "\n",
    "    # 隐藏层到输出层的连接\n",
    "    dot.edge('H1', 'O1')\n",
    "    dot.edge('H2', 'O1')\n",
    "    dot.edge('H3', 'O1')\n",
    "\n",
    "    # 返回图对象\n",
    "    return dot\n",
    "\n",
    "# 创建神经网络图\n",
    "nn_graph = create_neural_network_graph()\n",
    "\n",
    "# 输出图的源代码\n",
    "print(nn_graph.source)\n",
    "\n",
    "nn_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a2745dd",
   "metadata": {},
   "source": [
    "总结一下：\n",
    "\n",
    "人工神经网络的本质就是矩阵计算，指定输入、输出，然后在矩阵计算中拟合出合适的权重和偏置，从而实现输入到输出的映射。\n",
    "\n",
    "而这个映射并不是简单的线性映射，而是通过激活函数的非线性变换，从而实现复杂的非线性映射。\n",
    "\n",
    "矩阵计算是手段，但本质是概率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aizero-FmzNW-63-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "696483428f94258fb20f31ea19bb4743563cbacc675155017f0446f3f58b90c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
